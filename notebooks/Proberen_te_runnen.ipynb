{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "268f171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT REMOVE!\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e059bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The available device is cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available and determine the device\n",
    "if torch.cuda.is_available():\n",
    "  device = 'cuda'\n",
    "else:\n",
    "  device = 'cpu'\n",
    "\n",
    "print(f'The available device is {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5b2565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir = \"../results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13759d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT REMOVE\n",
    "PI = torch.from_numpy(np.asarray(np.pi))\n",
    "EPS = 1.e-5\n",
    "\n",
    "\n",
    "def log_categorical(x, p, num_classes=256, reduction=None, dim=None):\n",
    "    x_one_hot = F.one_hot(x.long(), num_classes=num_classes)\n",
    "    log_p = x_one_hot * torch.log(torch.clamp(p, EPS, 1. - EPS))\n",
    "    if reduction == 'avg':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "\n",
    "def log_bernoulli(x, p, reduction=None, dim=None):\n",
    "    pp = torch.clamp(p, EPS, 1. - EPS)\n",
    "    log_p = x * torch.log(pp) + (1. - x) * torch.log(1. - pp)\n",
    "    if reduction == 'avg':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "\n",
    "def log_normal_diag(x, mu, log_var, reduction=None, dim=None):\n",
    "    D = x.shape[1]\n",
    "    log_p = -0.5 * D * torch.log(2. * PI) - 0.5 * log_var - 0.5 * torch.exp(-log_var) * (x - mu)**2.\n",
    "    if reduction == 'avg':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "\n",
    "def log_standard_normal(x, reduction=None, dim=None):\n",
    "    D = x.shape[1]\n",
    "    log_p = -0.5 * D * torch.log(2. * PI) - 0.5 * x**2.\n",
    "    if reduction == 'avg':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66e8ac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, encoder_net):\n",
    "        # The init of the encoder network.\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = encoder_net\n",
    "        \n",
    "    # The reparameterization trick for Gaussians.\n",
    "    @staticmethod\n",
    "    def reparameterization(mu, log_var):\n",
    "        # The formula is the following: # z = mu + std ∗ epsilon\n",
    "        # epsilon ~ Normal(0,1)\n",
    "        \n",
    "        # First, we need to get std from log−variance.\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        \n",
    "        # Second, we sample epsilon from Normal(0,1).\n",
    "        eps = torch.randn_like(std)\n",
    "        \n",
    "        # The final output\n",
    "        return mu + std * eps\n",
    "    \n",
    "    # This function implements the output of the encoder network (i.e., parameters of a Gaussian).\n",
    "    def encode(self, x):\n",
    "        # First, we calculate the output of the encoder network of size 2M.\n",
    "        h_e = self.encoder(x)\n",
    "        # Second, we must divide the output to the mean and the log−variance.\n",
    "        mu_e, log_var_e = torch.chunk(h_e, 2, dim=1) # TODO error\n",
    "        return mu_e , log_var_e\n",
    "    \n",
    "    # Sampling procedure.\n",
    "    def sample(self, x=None, mu_e=None, log_var_e=None):\n",
    "        \"\"\"\n",
    "        Sample from the encoder. \n",
    "        If x is given (not equal to None), then copmute variational posterior distribution q(z|x) and sample from it.\n",
    "        Otherwise, use `mu_e` and `log_var_e` as parameter of the variational posterior and sample from it.\n",
    "\n",
    "        x: torch.tensor, with dimensionality (mini-batch, x_dim)\n",
    "             a mini-batch of data points\n",
    "        mu_e: torch.tensor, with dimensionality (mini-batch, x_dim)\n",
    "             mean vector of the variational posterior\n",
    "        log_var_e: torch.tensor, with dimensionality (mini-batch, x_dim)\n",
    "             log variance of the variational posterior\n",
    "        return: z: torch.tensor, with dimensionality (mini-batch, z_dim)\n",
    "        \"\"\"\n",
    "        #If we don’t provide a mean and a log−variance, we must first calculate it:\n",
    "        if (mu_e is None) and (log_var_e is None):\n",
    "            mu_e , log_var_e = self.encode(x)\n",
    "        # Or the final sample\n",
    "        else:\n",
    "        # Otherwise, we can simply apply the reparameterization trick!\n",
    "            if (mu_e is None) or (log_var_e is None):\n",
    "                raise ValueError('mu and log_var cannot be None')\n",
    "        z = self.reparameterization(mu_e, log_var_e)\n",
    "        return z\n",
    "    \n",
    "    # This function calculates the log−probability that is later used for calculating the ELBO.\n",
    "    # log q(z|x)\n",
    "    def log_prob(self, x=None, mu_e=None, log_var_e=None, z=None):\n",
    "        # If we provide x alone, then we can calculate a corresponding sample.\n",
    "        if x is not None:\n",
    "            mu_e, log_var_e = self.encode(x)\n",
    "            z = self.sample(mu_e=mu_e, log_var_e=log_var_e)\n",
    "        else:\n",
    "        # Otherwise, we should provide mu, log−var and z.\n",
    "            if (mu_e is None) or (log_var_e is None) or (z is None):\n",
    "                raise ValueError('mu, log_var and z cannot be None')\n",
    "        return log_normal_diag(z, mu_e, log_var_e)\n",
    "    \n",
    "    # PyTorch forward pass: it is either log−probability (by default) or sampling.\n",
    "    def forward(self, x, type = \"log_prob\"):\n",
    "        \"\"\"\n",
    "        Compute log-probability of variational posterior for given x, i.e., log q(z|x)\n",
    "        x: torch.tensor, with dimensionality (mini-batch, x_dim)\n",
    "             a mini-batch of data points\n",
    "        \"\"\"\n",
    "        assert type in [\"encode\", \"log_prob\"], 'Type can be either encode or log_prob'\n",
    "        if type == \"log_prob\":\n",
    "            return self.log_prob(x)\n",
    "        else:\n",
    "            return self.sample(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9db34f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "# NOTE: The class must containt the following function: \n",
    "# (i) sample\n",
    "# Moreover, forward must return the log-probability of the conditional likelihood function for given z, i.e., log p(x|z)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, decoder_net, distribution = \"categorical\", num_vals = None):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        # The decoder network.\n",
    "        self.decoder = decoder_net\n",
    "        # The distribution used for the decoder, categorical by default.\n",
    "        self.distribution = distribution\n",
    "        # The number of possible values. This is important for the categorical distribution.\n",
    "        self.num_vals = num_vals\n",
    "\n",
    "    # This function calculates parameters of the likelihood function p(x|z).\n",
    "    def decode(self, z):\n",
    "        # First, we apply the decoder network.\n",
    "        h_d = self.decoder(z)\n",
    "\n",
    "        # In this example, we use only the categorical distribution...\n",
    "        if self.distribution == \"categorical\":\n",
    "        # We save the shapes: batch size.\n",
    "            b = h_d.shape[0]\n",
    "        # and the dimensionality of x.\n",
    "            d = h_d.shape[1]//self.num_vals\n",
    "        # Then we reshape to (Batch size, Dimensionality, Number of Values).\n",
    "            h_d = h_d.view(b , d, self.num_vals)\n",
    "        # To get probabilities, we apply softmax.\n",
    "            mu_d = torch.softmax(h_d, 2)\n",
    "            return [mu_d]\n",
    "\n",
    "        elif self.distribution == \"bernoulli\":\n",
    "        # In the Bernoulli case, we have x_d \\in {0,1}.\n",
    "        # Therefore, it is enough to output a single probability, because\n",
    "        # p(x_d=1|z) = \\theta and p(x_d=0|z)=1-\\theta.\n",
    "            mu_d = torch.sigmoid(h_d)\n",
    "            return [mu_d]\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Only distribution options are categorical and bernoulli\")\n",
    "\n",
    "    # This function implements sampling from the decoder.\n",
    "    def sample(self, z):\n",
    "        \"\"\"\n",
    "        For a given latent code compute parameters of the conditional likelihood \n",
    "        and sample x ~ p(x|z)\n",
    "\n",
    "        z: torch.tensor, with dimensionality (mini-batch, z_dim)\n",
    "\n",
    "        return:\n",
    "        x: torch.tensor, with dimensionality (mini-batch, x_dim)\n",
    "        \"\"\"\n",
    "        outs = self.decode(z)\n",
    "\n",
    "        if self.distribution == \"categorical\":\n",
    "            # We take the output of the decoder, shape = (b, d, self.num_vals)\n",
    "            mu_d = outs[0]\n",
    "            # and save shapes (we will need that for reshaping).\n",
    "            b = mu_d.shape[0]\n",
    "            m = mu_d.shape[1]\n",
    "            # Here we use reshaping.\n",
    "        \n",
    "            # Daniel: This reshape is unnecessary? \n",
    "            mu_d = mu_d.view(mu_d.shape[0], -1, self.num_vals)\n",
    "\n",
    "            # flatten first two dimensions \n",
    "            p = mu_d.view(-1, self.num_vals)\n",
    "            \n",
    "            # Eventually, we sample from the categorical (the built-in PyTorch function).\n",
    "            # This generates a prediction for every pixel. Immediately reshape to (b,m,1)\n",
    "            x_new = torch.multinomial(p, num_samples =  1).view(b,m)\n",
    "        \n",
    "        elif self.distribution == \"bernoulli\":\n",
    "          # In the case of Bernoulli, we don't need any reshaping\n",
    "            mu_d = outs[0]\n",
    "          # and we can use the built-in PyTorch sampler.\n",
    "            x_new = torch.bernoulli(mu_d)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Only distribution options are categorical and bernoulli\")\n",
    "        \n",
    "        return x_new\n",
    "\n",
    "    def log_prob(self, x, z):\n",
    "        outs = self.decode(z)\n",
    "\n",
    "        if self.distribution == \"categorical\":\n",
    "            mu_d = outs[0]\n",
    "            # log likelihood from probabilities mu_d\n",
    "            log_p = log_categorical(x, mu_d, num_classes = self.num_vals,\n",
    "                                    reduction = \"sum\", dim = -1).sum(-1)\n",
    "        \n",
    "        elif self.distribution == \"bernoulli\":\n",
    "            mu_d = outs[0]\n",
    "            log_p = log_bernoulli(x, mu_d, reduction = \"sum\", dim = -1)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Only distribution options are categorical and bernoulli\")\n",
    "\n",
    "        return log_p\n",
    "\n",
    "    # The forward pass is either a log-prob or a sample.\n",
    "    def forward(self, z, x=None, type=\"log_prob\"):\n",
    "        \"\"\"\n",
    "        Compute the log probability: log p(x|z). \n",
    "        z: torch.tensor, with dimensionality (mini-batch, z_dim)\n",
    "        x: torch.tensor, with dimensionality (mini-batch, x_dim)\n",
    "        \"\"\"\n",
    "        assert type in [\"decoder\", \"log_prob\"], \"Type can be either decode or log_prob\"\n",
    "\n",
    "        if type == \"log_prob\":\n",
    "            # calculate the log likelihood log p(x|z)\n",
    "            return self.log_prob(x, z)\n",
    "        else:\n",
    "            # generate an image x^hat\n",
    "            return self.sample(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0cad090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "# NOTES:\n",
    "# (i) Implementing the standard Gaussian prior does not give you any points!\n",
    "# (ii) The function \"sample\" must be implemented.\n",
    "# (iii) The function \"forward\" must return the log-probability, i.e., log p(z)\n",
    "\n",
    "# The current implementation of the prior is very simple, namely, it is a\n",
    "# standard Gaussian. We could have used a built-in PyTorch distribution. However,\n",
    "# we didn't do so for two reasons:\n",
    "# (i) It is important to think of the prior as a crucial component in VAEs.\n",
    "# (ii) We can implement a learnable prior (e.g., a flow-based prior, VamPrior,\n",
    "# a mixture of distributions.)\n",
    "class Prior(nn.Module):\n",
    "    def __init__(self, L, device='cpu'): # deviation, the github code does not have device parameter\n",
    "        super(Prior, self).__init__()\n",
    "        self.device = device\n",
    "        self.L = L\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        z = torch.randn((batch_size, self.L))\n",
    "        return z\n",
    "\n",
    "    def forward(self, z):\n",
    "        return log_standard_normal(z)\n",
    "    \n",
    "    def log_prob(self, z):\n",
    "        return log_standard_normal(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a14bfd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "# This class combines Encoder, Decoder and Prior.\n",
    "# NOTES:\n",
    "# (i) The function \"sample\" must be implemented.\n",
    "# (ii) The function \"forward\" must return the negative ELBO. Please remember to add an argument \"reduction\" that is either \"mean\" or \"sum\".\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, encoder_net, decoder_net, num_vals = 256,\n",
    "                 L = 16, likelihood_type = \"categorical\", device='cpu'): # here again, 'device' is new parameter\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(encoder_net=encoder_net)\n",
    "        self.decoder = Decoder(distribution=likelihood_type, decoder_net=decoder_net,\n",
    "                               num_vals=num_vals)\n",
    "        self.prior = Prior(L = L)\n",
    "\n",
    "        self.num_vals = num_vals\n",
    "\n",
    "        self.likelihood_type = likelihood_type\n",
    "\n",
    "    def sample(self, batch_size=64):\n",
    "        z = self.prior.sample(batch_size=batch_size)\n",
    "        return self.decoder.sample(z)\n",
    "\n",
    "    def forward(self, x, reduction='mean'):\n",
    "        # encoder\n",
    "        mu_e, log_var_e, = self.encoder.encode(x) # TODO error\n",
    "        z = self.encoder.sample(mu_e = mu_e, log_var_e=log_var_e)\n",
    "        \n",
    "        # Negative ELBO (NELBO)\n",
    "        #NELBO = 0.\n",
    "        RE = self.decoder.log_prob(x, z)\n",
    "        KL = (self.prior.forward(z) - self.encoder.log_prob(mu_e = mu_e,\n",
    "                                                             log_var_e = log_var_e,\n",
    "                                                             z=z)).sum(-1)\n",
    "        NELBO = -(RE + KL)\n",
    "\n",
    "        if reduction == 'sum':\n",
    "            return NELBO.sum()\n",
    "        else:\n",
    "            return NELBO.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbf13f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT REMOVE\n",
    "\n",
    "def evaluation(test_loader, name=None, model_best=None, epoch=None):\n",
    "    # EVALUATION\n",
    "    if model_best is None:\n",
    "        # load best performing model\n",
    "        model_best = torch.load(name + '.model')\n",
    "\n",
    "    model_best.eval()\n",
    "    loss = 0.\n",
    "    N = 0.\n",
    "    for indx_batch, (test_batch, _) in enumerate(test_loader):\n",
    "#     for indx_batch, test_batch in enumerate(test_loader): # For Digits\n",
    "        test_batch = test_batch.to(device)\n",
    "        loss_t = model_best.forward(test_batch, reduction='sum')\n",
    "        loss = loss + loss_t.item()\n",
    "        N = N + test_batch.shape[0]\n",
    "    loss = loss / N\n",
    "\n",
    "    if epoch is None:\n",
    "        print(f'FINAL LOSS: nll={loss}')\n",
    "    else:\n",
    "        print(f'Epoch: {epoch}, val nll={loss}')\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def samples_real(name, test_loader, shape=(28,28)):\n",
    "    # real images-------\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = next(iter(test_loader))\n",
    "#     x, _ = next(iter(test_loader))\n",
    "    x = x.to('cpu').detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], shape)\n",
    "        ax.imshow(plottable_image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig(name+'_real_images.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def samples_generated(name, data_loader, shape=(28,28), extra_name=''):\n",
    "    x = next(iter(data_loader))\n",
    "#     x, _ = next(iter(data_loader))\n",
    "    x = x.to('cpu').detach().numpy()\n",
    "\n",
    "    # generations-------\n",
    "    model_best = torch.load(name + '.model')\n",
    "    model_best.eval()\n",
    "\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = model_best.sample(num_x * num_y)\n",
    "    x = x.to('cpu').detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], shape)\n",
    "        ax.imshow(plottable_image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig(name + '_generated_images' + extra_name + '.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_curve(name, nll_val):\n",
    "    plt.plot(np.arange(len(nll_val)), nll_val, linewidth='3')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('nll')\n",
    "    plt.savefig(name + '_nll_val_curve.pdf', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "492e42fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT REMOVE\n",
    "\n",
    "def training(name, max_patience, num_epochs, model, optimizer, training_loader,\n",
    "             val_loader, shape=(28,28)):\n",
    "    nll_val = []\n",
    "    best_nll = 1000.\n",
    "    patience = 0\n",
    "\n",
    "    # Main loop\n",
    "    for e in range(num_epochs):\n",
    "        # TRAINING\n",
    "        model.train()\n",
    "#         for indx_batch, batch in enumerate(training_loader): # for Digits\n",
    "        for indx_batch, (batch, _) in enumerate(training_loader):\n",
    "            batch = batch.to(device)\n",
    "            loss = model.forward(batch, reduction='mean') # TODO error\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        loss_val = evaluation(val_loader, model_best=model, epoch=e)\n",
    "        nll_val.append(loss_val)  # save for plotting\n",
    "\n",
    "        if e == 0:\n",
    "            print('saved!')\n",
    "            torch.save(model, name + '.model')\n",
    "            best_nll = loss_val\n",
    "        else:\n",
    "            if loss_val < best_nll:\n",
    "                print('saved!')\n",
    "                torch.save(model, name + '.model')\n",
    "                best_nll = loss_val\n",
    "                patience = 0\n",
    "\n",
    "                samples_generated(name, val_loader, shape=shape, extra_name=\"_epoch_\" + str(e))\n",
    "            else:\n",
    "                patience = patience + 1\n",
    "\n",
    "        if patience > max_patience:\n",
    "            break\n",
    "\n",
    "    nll_val = np.asarray(nll_val)\n",
    "\n",
    "    return nll_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d26d19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DEFINE APPROPRIATE TRANFORMS FOR THE DATASET\n",
    "transforms_train = torchvision.transforms.ToTensor()#,\n",
    "                    #torchvision.transforms.Normalize((0.1307,), (0.3081,))]\n",
    "\n",
    "transforms_test = torchvision.transforms.ToTensor()#[torchvision.transforms.ToTensor(),\n",
    "                   #torchvision.transforms.Normalize((0.1307,), (0.3081,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8db4f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JH: make sure to have directory \"VAE/results/vae/\", otherwise you'll get an error.\n",
    "\n",
    "# DO NOT REMOVE\n",
    "#-dataset\n",
    "dataset = MNIST('../results/', train=True, download=True,\n",
    "                      transform=transforms_train\n",
    "                )\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [50000, 10000], generator=torch.Generator().manual_seed(14))\n",
    "\n",
    "test_dataset = MNIST('../results/', train=False, download=True,\n",
    "                      transform=transforms_test\n",
    "                     )\n",
    "#-dataloaders\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#-creating a dir for saving results\n",
    "result_dir = images_dir + '/vae/'\n",
    "if not(os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)\n",
    "\n",
    "#-hyperparams (please do not modify them for the final report)\n",
    "num_epochs = 1000 # max. number of epochs\n",
    "max_patience = 20 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84eea006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "D = 28   # input dimension\n",
    "# D = 64 # for Digits dataset\n",
    "L = 16  # number of latents\n",
    "M = 256  # the number of neurons in scale (s) and translation (t) nets\n",
    "\n",
    "lr = 1e-3 # learning rate\n",
    "num_epochs = 1000 # max. number of epochs\n",
    "max_patience = 20 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4075982",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_type = 'categorical'\n",
    "\n",
    "# if likelihood_type == 'categorical':\n",
    "#     num_vals = 17\n",
    "# elif likelihood_type == 'bernoulli':\n",
    "#     num_vals = 1\n",
    "\n",
    "# encoder = nn.Sequential(nn.Linear(D, M), nn.LeakyReLU(),\n",
    "#                         nn.Linear(M, M), nn.LeakyReLU(),\n",
    "#                         nn.Linear(M, 2 * L))\n",
    "\n",
    "# decoder = nn.Sequential(nn.Linear(L, M), nn.LeakyReLU(),\n",
    "#                         nn.Linear(M, M), nn.LeakyReLU(),\n",
    "#                         nn.Linear(M, num_vals * D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dce470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D is gehardcode, D = 28. Verder weet ik niet of deze nets werken met trainen, maar\n",
    "# de shapes kloppen in elk geval wel.\n",
    "# inspiratie: https://towardsdatascience.com/building-a-convolutional-vae-in-pytorch-a0f54c947f71\n",
    "L = 4\n",
    "encoder = nn.Sequential(nn.Conv2d(1, 16, kernel_size = 3, stride = 1, padding = 1),\n",
    "                        nn.ReLU(), # size: batch, 1, 28, 28, \n",
    "                        nn.Conv2d(16, 32, kernel_size = 3, stride = 1, padding = 1),\n",
    "                        nn.ReLU(), \n",
    "                        nn.Flatten(1),\n",
    "                        nn.Linear(32*28*28, 2 * L))\n",
    "\n",
    "decoder = nn.Sequential(nn.Linear(L, 32*28*28),\n",
    "                        nn.ReLU(), # output shape: (batch, 32*28*28)\n",
    "                        nn.Unflatten(1, (32, 28, 28)),  # output shape: (batch, 32, 28, 28)\n",
    "                        nn.ConvTranspose2d(32, 64, kernel_size = 3, padding = 1),\n",
    "                        nn.ReLU(), #output (batch, 64, 28, 28)\n",
    "                        nn.ConvTranspose2d(64, 128, kernel_size = 3, padding = 1),\n",
    "                        nn.ReLU(),#output (batch, 128, 28, 28)\n",
    "                        nn.ConvTranspose2d(128, 256, kernel_size = 3, padding = 1),\n",
    "                        nn.ReLU(), #output (batch, 256, 28, 28)\n",
    "                        nn.Flatten(2),\n",
    "                        nn.Softmax(dim = -1)) # output (batch, 256, 28*28)\n",
    "\n",
    "\n",
    "num_vals = 256 \n",
    "L = 4 # number of latent variables\n",
    "batch = 2\n",
    "\n",
    "## Test net and shape ##\n",
    "# images = torch.randn(2, 1, 28, 28)\n",
    "# Z = torch.randn(batch, L)\n",
    "\n",
    "# encoder(images).shape # test if encoder works\n",
    "# p= decoder(Z).transpose(1,2).reshape(-1, num_vals) # test if decoder works and reshape to (b*28*28)\n",
    "# p.shape\n",
    "# x_hat = torch.multinomial(p, num_samples = 1).view(batch, 28,28) # sample using probabilities p and torch.multinomial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee29d792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6422528/(8*32*28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "318a5e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25088"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "32*28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59222291",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = torch.distributions.MultivariateNormal(torch.zeros(L), torch.eye(L))\n",
    "model = VAE(encoder_net=encoder, decoder_net=decoder, num_vals=num_vals, L=L, likelihood_type=likelihood_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f26bb06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE DEFINE YOUR OPTIMIZER\n",
    "optimizer = torch.optim.Adamax([p for p in model.parameters() if p.requires_grad == True], lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e237b06",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[32, 1, 256]' is invalid for input of size 6422528",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# DO NOT REMOVE OR MODIFY\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Training procedure\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m nll_val \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresult_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_patience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mtraining_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36mtraining\u001b[0;34m(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader, shape)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m indx_batch, (batch, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(training_loader):\n\u001b[1;32m     15\u001b[0m     batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 16\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# TODO error\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     19\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36mVAE.forward\u001b[0;34m(self, x, reduction)\u001b[0m\n\u001b[1;32m     27\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39msample(mu_e \u001b[38;5;241m=\u001b[39m mu_e, log_var_e\u001b[38;5;241m=\u001b[39mlog_var_e)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Negative ELBO (NELBO)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#NELBO = 0.\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m RE \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m KL \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprior\u001b[38;5;241m.\u001b[39mforward(z) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mlog_prob(mu_e \u001b[38;5;241m=\u001b[39m mu_e,\n\u001b[1;32m     33\u001b[0m                                                      log_var_e \u001b[38;5;241m=\u001b[39m log_var_e,\n\u001b[1;32m     34\u001b[0m                                                      z\u001b[38;5;241m=\u001b[39mz))\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     35\u001b[0m NELBO \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m(RE \u001b[38;5;241m+\u001b[39m KL)\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mDecoder.log_prob\u001b[0;34m(self, x, z)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, z):\n\u001b[0;32m---> 87\u001b[0m     outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribution \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     90\u001b[0m         mu_d \u001b[38;5;241m=\u001b[39m outs[\u001b[38;5;241m0\u001b[39m]\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mDecoder.decode\u001b[0;34m(self, z)\u001b[0m\n\u001b[1;32m     27\u001b[0m     d \u001b[38;5;241m=\u001b[39m h_d\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_vals\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Then we reshape to (Batch size, Dimensionality, Number of Values).\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     h_d \u001b[38;5;241m=\u001b[39m \u001b[43mh_d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_vals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# To get probabilities, we apply softmax.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     mu_d \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(h_d, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[32, 1, 256]' is invalid for input of size 6422528"
     ]
    }
   ],
   "source": [
    "# DO NOT REMOVE OR MODIFY\n",
    "# Training procedure\n",
    "nll_val = training(name=result_dir + name, max_patience=max_patience, \n",
    "                   num_epochs=num_epochs, model=model, optimizer=optimizer,\n",
    "                   training_loader=train_loader, val_loader=val_loader,\n",
    "                   shape=(28,28))\n",
    "#                    shape=(28,28)) # 'shape' argument here is not on github version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d8cd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14-12: Error in training > VAE.forward > Encoder.encode > torch.chunk\n",
    "# 18-12: Error in training > VAE.forward > Decoder.log_prob > Decoder.decode >\n",
    "# shape '[32, 1, 256]' is invalid for input of size 6422528\n",
    "\n",
    "# 6422528 = 28*28*32*256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d6c6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT REMOVE OR MODIFY\n",
    "# Final evaluation\n",
    "test_loss = evaluation(name=result_dir + name, test_loader=test_loader)\n",
    "f = open(result_dir + name + '_test_loss.txt', \"w\")\n",
    "f.write(str(test_loss))\n",
    "f.close()\n",
    "\n",
    "samples_real(result_dir + name, test_loader, shape = (28,28))\n",
    "samples_generated(result_dir + name, test_loader, extra_name='_FINAL', shape = (28,28))\n",
    "\n",
    "plot_curve(result_dir + name, nll_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aae1a1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for indx_batch, (batch, _) in enumerate(train_loader):\n",
    "    if indx_batch < 2:\n",
    "        print(batch.shape)\n",
    "#         for indx_batch, (batch, _) in enumerate(training_loader):\n",
    "#     batch = batch.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1829ab",
   "metadata": {},
   "source": [
    "# To run with Digits dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80916698",
   "metadata": {},
   "source": [
    "In this example, we go wild and use a dataset that is simpler than MNIST! We use a scipy dataset called Digits. It consists of ~1500 images of size 8x8, and each pixel can take values in \n",
    "{\n",
    "0\n",
    ",\n",
    "1\n",
    ",\n",
    "…\n",
    ",\n",
    "16\n",
    "}\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c13f332",
   "metadata": {},
   "source": [
    "MNIST: size 28x28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd54aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58820fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Digits(Dataset):\n",
    "    \"\"\"Scikit-Learn Digits dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, mode='train', transforms=None):\n",
    "        digits = load_digits()\n",
    "        if mode == 'train':\n",
    "            self.data = digits.data[:1000].astype(np.float32)\n",
    "        elif mode == 'val':\n",
    "            self.data = digits.data[1000:1350].astype(np.float32)\n",
    "        else:\n",
    "            self.data = digits.data[1350:].astype(np.float32)\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec5ca950",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Digits(mode='train')\n",
    "val_data = Digits(mode='val')\n",
    "test_data = Digits(mode='test')\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "result_dir = './results/'\n",
    "if not(os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)\n",
    "name = 'vae'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "008e60de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 64])\n",
      "torch.Size([64, 64])\n"
     ]
    }
   ],
   "source": [
    "for indx_batch, batch in enumerate(train_loader):\n",
    "    if indx_batch < 2:\n",
    "        print(batch.shape)\n",
    "#         for indx_batch, (batch, _) in enumerate(training_loader):\n",
    "#     batch = batch.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231f62e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "16*16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94c26c8",
   "metadata": {},
   "source": [
    "Information:\n",
    "- name : MNIST\n",
    "- length : 70000\n",
    "\n",
    "Input Summary:\n",
    "- shape : (28, 28, 1)\n",
    "- range : (0.0, 1.0)\n",
    "\n",
    "Target Summary:\n",
    "- shape : (10,)\n",
    "- range : (0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07d3be4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
